{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_network_layer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/yutinglaitw/learning-tensorflow/blob/master/2_NeuralNetworks/neural_network_tl.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "shCEL9YozoxR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network Example (TensorLayer)\n",
        "\n",
        "用 TensorLayer 實作多層感知機 (Multi-Layer Perceptron, MLP) \n",
        "\n",
        "以 MNIST 為例實作一個有兩層隱含層的 Fully Connected Network\n"
      ]
    },
    {
      "metadata": {
        "id": "4vk0ibx91HpM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install TensorLayer"
      ]
    },
    {
      "metadata": {
        "id": "kvIDzs9Y1NA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip install tensorlayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXzmRIlY3o29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "cp8NoucWx8hW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dYRIuKEa4Dtn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2-Layer Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "5tFHRdqW_ovB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Network Parameters\n",
        "h1_units = 256\n",
        "h2_units = 256\n",
        "num_classes = 10\n",
        "\n",
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "epochs = 1000\n",
        "print_freq = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFM-OdWC8yID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7f52b7c1-8458-479b-9ed1-3faf05b25183"
      },
      "cell_type": "code",
      "source": [
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# Data\n",
        "x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
        "y_ = tf.placeholder(tf.int64, shape=[None], name='y_')\n",
        "\n",
        "# Define network\n",
        "network = tl.layers.InputLayer(x, name='input')\n",
        "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')\n",
        "network = tl.layers.DenseLayer(network, h1_units, tf.nn.relu, name='relu1')\n",
        "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop2')\n",
        "network = tl.layers.DenseLayer(network, h2_units, tf.nn.relu, name='relu2')\n",
        "network = tl.layers.DropoutLayer(network, keep=0.8, name='drop3')\n",
        "network = tl.layers.DenseLayer(network, n_units=num_classes, act=None, name='output')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TL] InputLayer  input: (?, 784)\n",
            "[TL] DropoutLayer drop1: keep: 0.800000 is_fix: False\n",
            "[TL] DenseLayer  relu1: 256 relu\n",
            "[TL] DropoutLayer drop2: keep: 0.800000 is_fix: False\n",
            "[TL] DenseLayer  relu2: 256 relu\n",
            "[TL] DropoutLayer drop3: keep: 0.800000 is_fix: False\n",
            "[TL] DenseLayer  output: 10 No Activation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9-Fik5XVsjq3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define cost function and metric.\n",
        "y = network.outputs\n",
        "cost = tl.cost.cross_entropy(y, y_, name='cost')\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n",
        "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "y_op = tf.argmax(tf.nn.softmax(y), 1)\n",
        "\n",
        "\n",
        "# Define the optimizer\n",
        "train_params = network.all_params\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost, var_list=train_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qDzOzMK-T0K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "WyitUOH481_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5202
        },
        "outputId": "f9c958db-ca21-4c90-e2de-6cf72180e257"
      },
      "cell_type": "code",
      "source": [
        "# Initialize all variables in the session\n",
        "tl.layers.initialize_global_variables(sess)\n",
        "\n",
        "# Train the network\n",
        "tl.utils.fit(sess, network, train_op, cost, mnist.train.images, mnist.train.labels, \\\n",
        "             x, y_, acc=acc, batch_size=batch_size , n_epoch=epochs, print_freq=print_freq, \\\n",
        "             X_val=mnist.validation.images, y_val=mnist.validation.labels, eval_train=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TL] Start training the network ...\n",
            "[TL] Epoch 1 of 1000 took 1.828965s\n",
            "[TL]    val loss: 0.143813\n",
            "[TL]    val acc: 0.959400\n",
            "[TL] Epoch 10 of 1000 took 1.983340s\n",
            "[TL]    val loss: 0.057767\n",
            "[TL]    val acc: 0.983000\n",
            "[TL] Epoch 20 of 1000 took 1.959984s\n",
            "[TL]    val loss: 0.054364\n",
            "[TL]    val acc: 0.983800\n",
            "[TL] Epoch 30 of 1000 took 1.968281s\n",
            "[TL]    val loss: 0.059581\n",
            "[TL]    val acc: 0.985800\n",
            "[TL] Epoch 40 of 1000 took 1.971300s\n",
            "[TL]    val loss: 0.054786\n",
            "[TL]    val acc: 0.987800\n",
            "[TL] Epoch 50 of 1000 took 1.964370s\n",
            "[TL]    val loss: 0.068708\n",
            "[TL]    val acc: 0.985400\n",
            "[TL] Epoch 60 of 1000 took 1.959910s\n",
            "[TL]    val loss: 0.064144\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 70 of 1000 took 1.974140s\n",
            "[TL]    val loss: 0.060228\n",
            "[TL]    val acc: 0.988200\n",
            "[TL] Epoch 80 of 1000 took 1.961214s\n",
            "[TL]    val loss: 0.068161\n",
            "[TL]    val acc: 0.986400\n",
            "[TL] Epoch 90 of 1000 took 1.961785s\n",
            "[TL]    val loss: 0.063368\n",
            "[TL]    val acc: 0.987400\n",
            "[TL] Epoch 100 of 1000 took 1.965247s\n",
            "[TL]    val loss: 0.070957\n",
            "[TL]    val acc: 0.985400\n",
            "[TL] Epoch 110 of 1000 took 1.964699s\n",
            "[TL]    val loss: 0.081044\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 120 of 1000 took 1.996492s\n",
            "[TL]    val loss: 0.068488\n",
            "[TL]    val acc: 0.987600\n",
            "[TL] Epoch 130 of 1000 took 1.949603s\n",
            "[TL]    val loss: 0.074468\n",
            "[TL]    val acc: 0.987000\n",
            "[TL] Epoch 140 of 1000 took 1.952466s\n",
            "[TL]    val loss: 0.076928\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 150 of 1000 took 1.969450s\n",
            "[TL]    val loss: 0.079075\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 160 of 1000 took 1.988955s\n",
            "[TL]    val loss: 0.087718\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 170 of 1000 took 1.965155s\n",
            "[TL]    val loss: 0.084357\n",
            "[TL]    val acc: 0.985200\n",
            "[TL] Epoch 180 of 1000 took 1.950937s\n",
            "[TL]    val loss: 0.090504\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 190 of 1000 took 1.966411s\n",
            "[TL]    val loss: 0.095084\n",
            "[TL]    val acc: 0.984200\n",
            "[TL] Epoch 200 of 1000 took 1.979422s\n",
            "[TL]    val loss: 0.100137\n",
            "[TL]    val acc: 0.984400\n",
            "[TL] Epoch 210 of 1000 took 1.972979s\n",
            "[TL]    val loss: 0.089279\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 220 of 1000 took 1.980855s\n",
            "[TL]    val loss: 0.094116\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 230 of 1000 took 1.959348s\n",
            "[TL]    val loss: 0.084637\n",
            "[TL]    val acc: 0.985000\n",
            "[TL] Epoch 240 of 1000 took 1.972947s\n",
            "[TL]    val loss: 0.092208\n",
            "[TL]    val acc: 0.987200\n",
            "[TL] Epoch 250 of 1000 took 1.938468s\n",
            "[TL]    val loss: 0.096764\n",
            "[TL]    val acc: 0.985800\n",
            "[TL] Epoch 260 of 1000 took 1.966973s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[TL]    val loss: 0.085710\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 270 of 1000 took 1.972724s\n",
            "[TL]    val loss: 0.092049\n",
            "[TL]    val acc: 0.985200\n",
            "[TL] Epoch 280 of 1000 took 1.969463s\n",
            "[TL]    val loss: 0.109697\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 290 of 1000 took 1.982111s\n",
            "[TL]    val loss: 0.100274\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 300 of 1000 took 1.953379s\n",
            "[TL]    val loss: 0.112674\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 310 of 1000 took 1.937564s\n",
            "[TL]    val loss: 0.105901\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 320 of 1000 took 1.957191s\n",
            "[TL]    val loss: 0.115952\n",
            "[TL]    val acc: 0.984600\n",
            "[TL] Epoch 330 of 1000 took 1.978619s\n",
            "[TL]    val loss: 0.105249\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 340 of 1000 took 1.968930s\n",
            "[TL]    val loss: 0.110330\n",
            "[TL]    val acc: 0.984600\n",
            "[TL] Epoch 350 of 1000 took 1.932151s\n",
            "[TL]    val loss: 0.104439\n",
            "[TL]    val acc: 0.985800\n",
            "[TL] Epoch 360 of 1000 took 1.967317s\n",
            "[TL]    val loss: 0.119586\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 370 of 1000 took 1.966944s\n",
            "[TL]    val loss: 0.121382\n",
            "[TL]    val acc: 0.987600\n",
            "[TL] Epoch 380 of 1000 took 1.950204s\n",
            "[TL]    val loss: 0.140256\n",
            "[TL]    val acc: 0.984000\n",
            "[TL] Epoch 390 of 1000 took 1.956677s\n",
            "[TL]    val loss: 0.106724\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 400 of 1000 took 1.989803s\n",
            "[TL]    val loss: 0.107012\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 410 of 1000 took 1.958266s\n",
            "[TL]    val loss: 0.100536\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 420 of 1000 took 1.968841s\n",
            "[TL]    val loss: 0.114903\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 430 of 1000 took 1.959805s\n",
            "[TL]    val loss: 0.110889\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 440 of 1000 took 1.911485s\n",
            "[TL]    val loss: 0.095080\n",
            "[TL]    val acc: 0.985800\n",
            "[TL] Epoch 450 of 1000 took 1.957740s\n",
            "[TL]    val loss: 0.109068\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 460 of 1000 took 1.970608s\n",
            "[TL]    val loss: 0.108397\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 470 of 1000 took 1.987960s\n",
            "[TL]    val loss: 0.112151\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 480 of 1000 took 1.961811s\n",
            "[TL]    val loss: 0.115585\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 490 of 1000 took 1.893763s\n",
            "[TL]    val loss: 0.101624\n",
            "[TL]    val acc: 0.985800\n",
            "[TL] Epoch 500 of 1000 took 1.884090s\n",
            "[TL]    val loss: 0.097253\n",
            "[TL]    val acc: 0.984600\n",
            "[TL] Epoch 510 of 1000 took 1.914540s\n",
            "[TL]    val loss: 0.115030\n",
            "[TL]    val acc: 0.985800\n",
            "[TL] Epoch 520 of 1000 took 1.966352s\n",
            "[TL]    val loss: 0.106943\n",
            "[TL]    val acc: 0.986000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[TL] Epoch 530 of 1000 took 1.983917s\n",
            "[TL]    val loss: 0.108074\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 540 of 1000 took 1.955977s\n",
            "[TL]    val loss: 0.123553\n",
            "[TL]    val acc: 0.985800\n",
            "[TL] Epoch 550 of 1000 took 1.944492s\n",
            "[TL]    val loss: 0.117172\n",
            "[TL]    val acc: 0.985200\n",
            "[TL] Epoch 560 of 1000 took 1.955517s\n",
            "[TL]    val loss: 0.132080\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 570 of 1000 took 1.953650s\n",
            "[TL]    val loss: 0.121947\n",
            "[TL]    val acc: 0.984800\n",
            "[TL] Epoch 580 of 1000 took 1.971601s\n",
            "[TL]    val loss: 0.126502\n",
            "[TL]    val acc: 0.985800\n",
            "[TL] Epoch 590 of 1000 took 1.976097s\n",
            "[TL]    val loss: 0.123481\n",
            "[TL]    val acc: 0.985400\n",
            "[TL] Epoch 600 of 1000 took 1.951275s\n",
            "[TL]    val loss: 0.108449\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 610 of 1000 took 1.971896s\n",
            "[TL]    val loss: 0.125188\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 620 of 1000 took 2.007058s\n",
            "[TL]    val loss: 0.120700\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 630 of 1000 took 1.982303s\n",
            "[TL]    val loss: 0.123502\n",
            "[TL]    val acc: 0.985800\n",
            "[TL] Epoch 640 of 1000 took 1.965654s\n",
            "[TL]    val loss: 0.127069\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 650 of 1000 took 1.949419s\n",
            "[TL]    val loss: 0.122489\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 660 of 1000 took 1.973740s\n",
            "[TL]    val loss: 0.134267\n",
            "[TL]    val acc: 0.986400\n",
            "[TL] Epoch 670 of 1000 took 1.962811s\n",
            "[TL]    val loss: 0.126174\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 680 of 1000 took 1.973588s\n",
            "[TL]    val loss: 0.126435\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 690 of 1000 took 1.975260s\n",
            "[TL]    val loss: 0.119649\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 700 of 1000 took 1.959960s\n",
            "[TL]    val loss: 0.145999\n",
            "[TL]    val acc: 0.985200\n",
            "[TL] Epoch 710 of 1000 took 1.964618s\n",
            "[TL]    val loss: 0.119131\n",
            "[TL]    val acc: 0.986400\n",
            "[TL] Epoch 720 of 1000 took 1.976181s\n",
            "[TL]    val loss: 0.133759\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 730 of 1000 took 1.960053s\n",
            "[TL]    val loss: 0.133990\n",
            "[TL]    val acc: 0.987600\n",
            "[TL] Epoch 740 of 1000 took 1.903128s\n",
            "[TL]    val loss: 0.130712\n",
            "[TL]    val acc: 0.987400\n",
            "[TL] Epoch 750 of 1000 took 1.944754s\n",
            "[TL]    val loss: 0.139820\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 760 of 1000 took 1.937655s\n",
            "[TL]    val loss: 0.141191\n",
            "[TL]    val acc: 0.986400\n",
            "[TL] Epoch 770 of 1000 took 1.898585s\n",
            "[TL]    val loss: 0.130532\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 780 of 1000 took 1.964751s\n",
            "[TL]    val loss: 0.125488\n",
            "[TL]    val acc: 0.987400\n",
            "[TL] Epoch 790 of 1000 took 1.920770s\n",
            "[TL]    val loss: 0.152204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[TL]    val acc: 0.986400\n",
            "[TL] Epoch 800 of 1000 took 1.929408s\n",
            "[TL]    val loss: 0.163728\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 810 of 1000 took 1.966716s\n",
            "[TL]    val loss: 0.144550\n",
            "[TL]    val acc: 0.985000\n",
            "[TL] Epoch 820 of 1000 took 1.861405s\n",
            "[TL]    val loss: 0.142819\n",
            "[TL]    val acc: 0.987600\n",
            "[TL] Epoch 830 of 1000 took 1.915195s\n",
            "[TL]    val loss: 0.152293\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 840 of 1000 took 1.919570s\n",
            "[TL]    val loss: 0.125347\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 850 of 1000 took 1.938228s\n",
            "[TL]    val loss: 0.150250\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 860 of 1000 took 1.948293s\n",
            "[TL]    val loss: 0.126953\n",
            "[TL]    val acc: 0.986600\n",
            "[TL] Epoch 870 of 1000 took 1.977601s\n",
            "[TL]    val loss: 0.156652\n",
            "[TL]    val acc: 0.985200\n",
            "[TL] Epoch 880 of 1000 took 1.997009s\n",
            "[TL]    val loss: 0.138929\n",
            "[TL]    val acc: 0.984200\n",
            "[TL] Epoch 890 of 1000 took 1.937013s\n",
            "[TL]    val loss: 0.161090\n",
            "[TL]    val acc: 0.985400\n",
            "[TL] Epoch 900 of 1000 took 1.958620s\n",
            "[TL]    val loss: 0.133781\n",
            "[TL]    val acc: 0.985400\n",
            "[TL] Epoch 910 of 1000 took 1.982688s\n",
            "[TL]    val loss: 0.139491\n",
            "[TL]    val acc: 0.985600\n",
            "[TL] Epoch 920 of 1000 took 1.975114s\n",
            "[TL]    val loss: 0.146788\n",
            "[TL]    val acc: 0.985400\n",
            "[TL] Epoch 930 of 1000 took 1.976757s\n",
            "[TL]    val loss: 0.149108\n",
            "[TL]    val acc: 0.986000\n",
            "[TL] Epoch 940 of 1000 took 1.934461s\n",
            "[TL]    val loss: 0.166792\n",
            "[TL]    val acc: 0.982600\n",
            "[TL] Epoch 950 of 1000 took 1.959321s\n",
            "[TL]    val loss: 0.116597\n",
            "[TL]    val acc: 0.986400\n",
            "[TL] Epoch 960 of 1000 took 1.967126s\n",
            "[TL]    val loss: 0.142042\n",
            "[TL]    val acc: 0.986400\n",
            "[TL] Epoch 970 of 1000 took 1.992748s\n",
            "[TL]    val loss: 0.135149\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Epoch 980 of 1000 took 1.958671s\n",
            "[TL]    val loss: 0.152645\n",
            "[TL]    val acc: 0.985000\n",
            "[TL] Epoch 990 of 1000 took 1.978305s\n",
            "[TL]    val loss: 0.145665\n",
            "[TL]    val acc: 0.984800\n",
            "[TL] Epoch 1000 of 1000 took 1.978119s\n",
            "[TL]    val loss: 0.128708\n",
            "[TL]    val acc: 0.986200\n",
            "[TL] Total training time: 1971.294176s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k5l19BNC-GWL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ]
    },
    {
      "metadata": {
        "id": "BJU7oAId3co1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e1d0f5f9-a19d-445c-a370-f49175a43e7c"
      },
      "cell_type": "code",
      "source": [
        "tl.utils.test(sess, network, acc, mnist.test.images, mnist.test.labels, x, y_, batch_size=None, cost=cost)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TL] Start testing the network ...\n",
            "[TL]    test loss: 0.146023\n",
            "[TL]    test acc: 0.984700\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}